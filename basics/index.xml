<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Список вопросов к экзамену по курсу основы программирования СПбГУ, весенний семестр, 2024/25 учебный год :: Краткий курс по основам программирования</title>
    <link>https://apmath-spbu.github.io/basics/index.html</link>
    <description>$O, \Omega, \Theta, o, \omega$ : определения и базовые свойства. Сравнение скорости роста полилогарифмических, полиномиальных и экспоненциальных функций. Алгоритм сложения за $O(n)$. Алгоритмы умножения за $O\left(n^{2}\right)$. Алгоритмы деления за $O\left(n^{2}\right)$. Алгоритм Карацубы. Основная теорема о рекуррентных соотношениях. Доказательство оценки $O$ в общем случае, оценки $\Theta$ в случае $n=b^{k}$. Массив, динамический массив, cвязный список, стек, очередь, дек. Двоичный поиск, поиск левого (правого) вхождения. Двоичный поиск по функции, двоичный поиск по функции с вещественным аргументом. Метод двух указателей на примере задачи о поиске в массиве неотрицательных чисел максимального по длине подотрезка, сумма на котором не превосходит $M$. Сортировка выбором, сортировка вставками. Оценка времени работы сортировки вставками через число инверсий в массиве. Стабильность. Сортировка слиянием. Быстрая сортировка. Корректность работы функции partition. Быстрая сортировка. Оценка времени работы. Поиск $k$-й порядковой статистики. Оценка времени работы. Оценка снизу на время работы сортировки сравнениями. Сортировка подсчётом. Стабильная версия. Поразрядная сортировка. Двоичная куча. Операции getMin, siftUp, siftDown, insert и extractMin. Двоичная куча. Построение за линейное время. Двоичная куча. Heapsort, очередь с приоритетами, удаление или изменение произвольного элемента. Хеш-таблица. Метод цепочек. Хеш-таблица. Открытая адресация, способы выбора последовательности проб, удаление элементов. Сортировка Киркпатрика-Рейша. Универсальное хеширование. Оценка времени работы операций на хеш-таблице при использовании техники универального хеширования. Универсальное хеширование. Построение универсального семейства хеш-функций. Совершенное хеширование. Оценка вероятности отсутствия коллизий при хранении $n$ ключей в хеш-таблице размера $n^{2}$ с использованием техники универсального хеширования. Совершенное хеширование. Оценка суммарного размера внутренних хеш-таблиц. Сложение, умножение и возведение в степень по модулю $N$. Алгоритм Евклида. Оценки времени работы $O(n \cdot M(n))$ и $O\left(n^{2}\right)$. Расширенный алгоритм Евклида. Доказательство корректности. Нахождение обратного по модулю $N$. Расширенный алгоритм Евклида. Оценки времени работы $O(n \cdot M(n))$ и $O\left(n^{2}\right)$. Решето Эратосфена. Решето с линейным временем работы. Тест Ферма. Оценка вероятности ошибки для $n$, не являющихся числами Кармайкла. Тест Миллера-Рабина. Оценка вероятности ошибки. $\rho$-алгоритм Полларда. Описание, эвристическая оценка времени работы. $\rho$-алгоритм Полларда. Оценка вероятности того, что для случайных $f: \mathbb{Z}_{p} \rightarrow \mathbb{Z}_{p}, x_{0} \in \mathbb{Z}_{p}$ элементы последовательности $x_{i}=f\left(x_{i-1}\right)$ с номерами не более $\sqrt{2 \lambda p}$ попарно различны. Схема RSA. Цифровая подпись. Цифровой сертификат. Протокол Диффи-Хеллмана. Схема Эль-Гамаля. DFS. Обход вершин, достижимых из данной. Поиск компонент связности. DFS. Дерево поиска в глубину в неориентированном/ориентированном графе. Времена входа и выхода. Типы рёбер. DFS. Поиск цикла в неориентированном/ориентированном графе. DFS. Топологическая сортировка. DFS. Поиск компонент сильной связности. DFS. Поиск мостов и компонент рёберной двусвязности. DFS. Поиск точек сочленения и компонент вершинной двусвязности. DFS. Решение задачи 2-SAT. BFS. Дерево кратчайших путей. $0-1 \mathrm{BFS}$. $1-k$ BFS (две реализации). Алгоритм Дейкстры. Алгоритм А*. Доказательство корректности работы для функции, удовлетворяющей неравенству треугольника. Сравнение с алгоритмом Дейкстры с break. Алгоритм Форда-Беллмана. Алгоритм Форда-Беллмана. Поиск отрицательного цикла. Алгоритм Форда-Беллмана с очередью. Алгоритм Флойда. Поиск отрицательного цикла и проверка существования кратчайшего пути между вершинами с помощью алгоритма Флойда. Префиксные коды, связь с двоичными деревьями. Алгоритм Хаффмана. Алгоритм Белади. Лемма о разрезе. Алгоритм Прима. Лемма о разрезе. Алгоритм Краскала. DSU. Реализация связными списками. DSU. Реализация деревьями. Ранговая эвристика. DSU. Реализация деревьями. Эвристика сжатия путей. DSU. Совместное использование эвристик. ДП. Наибольшая общая подпоследовательность. ДП. Расстояние Левенштейна. ДП. Алгоритм Хиршберга. ДП. Наибольшая возрастающая подпоследовательность. Решение за $O(n \log n)$. ДП. Задача о рюкзаке. Версии “с повторениями” и “без повторений”. ДП. Произведение матриц. ДП. Независимое множество максимального веса в дереве. ДП. Задача коммивояжёра. ДП. Размер подмножеств, сумма элементов в подмножестве, сумма по подмножествам. ДП. Генерация перестановки по номеру и номера по перестановке. ДП. Генерация ПСП по номеру и номера по ПСП.</description>
    <generator>Hugo</generator>
    <language>ru-ru</language>
    <lastBuildDate>Thu, 24 Apr 2025 15:33:10 +0300</lastBuildDate>
    <atom:link href="https://apmath-spbu.github.io/basics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>1. Анализ сложности алгоритмов</title>
      <link>https://apmath-spbu.github.io/basics/complexity/index.html</link>
      <pubDate>Sat, 15 Feb 2025 22:06:42 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/complexity/index.html</guid>
      <description>Вычисление чисел Фибоначчи Последовательность чисел Фибоначчи&#xA;$$ 1,1,2,3,5,8,13,21,34,55,89, \ldots $$определяется следующим образом:&#xA;Определение 1.1.1 $F_{n}$ - $n$-ое число Фибоначчи, где $F_{0}=F_{1}=1, F_{n}=F_{n-1}+F_{n-2}, n&gt;1 .$&#xA;Числа Фибоначчи растут экспоненциально быстро:&#xA;Лемма 1.1.1 $2^{\lfloor n / 2\rfloor} \leqslant F_{n} \leqslant 2^{n}$. Доказательство Докажем утверждение по индукции.</description>
    </item>
    <item>
      <title>2. Элементарная арифметика</title>
      <link>https://apmath-spbu.github.io/basics/elementary_arithmetic/index.html</link>
      <pubDate>Sat, 15 Feb 2025 22:36:51 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/elementary_arithmetic/index.html</guid>
      <description>Современные компьютеры умеют за одну элементарную операцию складывать два 32(или 64)-битных числа. Часто (например, в криптографии) приходится работать с куда более длинными числами. Поговорим о том, как проводить с ними элементарные арифметические операции.&#xA;Для удобства будем считать, что на вход алгоритмам даются натуральные числа в двоичной записи. Мы будем работать с числами, имеющими двоичную запись длины $n$ (возможно, с ведущими нулями).&#xA;✍️ В произвольном случае можно применить соответствующий алгоритм для $n$ равного максимуму из длин чисел, а в конце определить длину записи результата применения операции (удалить ведущие нули), что потребует $O(n)$ операций и не повлияет на оценку сложности алгоритма.</description>
    </item>
    <item>
      <title>3. Рекурентные соотношения</title>
      <link>https://apmath-spbu.github.io/basics/recurrence_relation/index.html</link>
      <pubDate>Sun, 16 Feb 2025 11:32:04 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/recurrence_relation/index.html</guid>
      <description>Основная теорема о рекуррентных соотношениях Алгоритм Карацубы - пример применения метода “разделяй и властвуй” (“divide-and-conquer”), с которым мы ещё не раз встретимся.&#xA;Идея этого метода состоит в том, чтобы свести решение задачи к решению нескольких подзадач в несколько раз меньшего размера, после чего восстановить решение исходной задачи с помощью решений подзадач. Сейчас мы докажем достаточно общую теорему, применимую к оценке многих алгоритмов, использующих метод “разделяй и властвуй”.&#xA;Основная теорема о рекуррентных соотношениях Пусть $T(n)=a \cdot T\left(\left\lceil\frac{n}{b}\right\rceil\right)+\Theta\left(n^{c}\right)$, где $a&gt;0, b&gt;1, c \geqslant 0$. Тогда</description>
    </item>
    <item>
      <title>4. Базовые структуры данных</title>
      <link>https://apmath-spbu.github.io/basics/basic_data_structures/index.html</link>
      <pubDate>Sun, 16 Feb 2025 12:32:57 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/basic_data_structures/index.html</guid>
      <description>Массив Массив (array) - структура данных, позволяющая хранить набор значений в ячейках, пронумерованных индексами (или набором индексов в случае многомерного массива) из некоторого отрезка целых чисел. Встроен в большинство современных языков программирования.&#xA;Массив позволяет за константное $(O(1))$ время получать доступ к элементу по индексу, а также изменять этот элемент. При этом массив имеет фиксированный размер, поэтому не поддерживает операций вставки и удаления элементов. Если хочется вставить или удалить элемент, можно создать новый массив нужного размера и скопировать информацию в него, но это потребует $\Theta(n)$ операций, где $n$ - длина массива.</description>
    </item>
    <item>
      <title>5. Двоичный поиск</title>
      <link>https://apmath-spbu.github.io/basics/binary_search/index.html</link>
      <pubDate>Sun, 16 Feb 2025 12:46:35 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/binary_search/index.html</guid>
      <description>Двоичный поиск Если элементы массива расположены в возрастающем порядке (то есть массив отсортирован), то искать элемент в массиве можно быстрее, чем за линейное время.&#xA;Пусть мы хотим найти $x$ в отсортированном массиве $a$ длины $n$. Снова применим идею метода “разделяй и властвуй”: посмотрим на элемент в середине массива - $a\left[\frac{n}{2}\right]$. Если $a\left[\frac{n}{2}\right]=x$, то мы нашли $x$ в массиве $a$. Если $a\left[\frac{n}{2}\right]&gt;x$, то $x$ может найтись только в $a\left[0,1, \ldots, \frac{n}{2}-1\right]$. Если же $a\left[\frac{n}{2}\right] &lt; x$, то $x$ может найтись только в $a\left[\frac{n}{2}+1, \ldots, n-1\right]$. В любом из последних двух случаев, мы вдвое уменьшили длину отрезка, на котором нужно искать $x$.</description>
    </item>
    <item>
      <title>6. Сортировки</title>
      <link>https://apmath-spbu.github.io/basics/sorts/index.html</link>
      <pubDate>Sun, 23 Feb 2025 13:44:51 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/sorts/index.html</guid>
      <description>Квадратичные сортировки Существует множество различных алгоритмов, сортирующих массив длины $n$ за $\Theta\left(n^{2}\right)$. Мы поговорим лишь о двух из них.&#xA;Сортировка выбором Сортировка выбором (selection sort) на $i$-м шаге находит $i$-й по возрастанию элемент и ставит его на $i$-ю позицию. Поскольку первые $i-1$ элементов в этот момент уже стоят на своих позициях, достаточно просто найти минимальный элемент в подотрезке $[i, n)$.&#xA;1 2 3 4 5 6 for i = 0..(n - 1): minPos = i for j = (i + 1)..(n - 1): if a[minPos] &gt; a[j]: minPos = j swap(a[i], a[minPos])</description>
    </item>
    <item>
      <title>7. Двоичная куча</title>
      <link>https://apmath-spbu.github.io/basics/heap/index.html</link>
      <pubDate>Sun, 02 Mar 2025 11:30:34 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/heap/index.html</guid>
      <description>Пусть мы хотим поддерживать множество элементов и быстро выполнять на нём следующие операции: добавлять и удалять элементы, а также находить минимум.&#xA;Можно попытаться сделать это с помощью динамического массива или списка. Тогда мы сможем добавлять и удалять элементы за $O(1)$ (чтобы быстро удалить элемент из массива, поменяем его местами с последним элементом, после чего уменьшим длину массива на один). Однако быстро находить минимум не получится: можно пытаться поддерживать указатель на минимальный элемент, но после каждого удаления минимума новый минимум получится найти лишь перебором всех оставшихся элементов за $\Theta(n)$ (где $n$ - число элементов в множестве). Можно было бы поддерживать массив в отсортированном порядке (тогда минимум всегда будет в начале), но тогда не получится быстро добавлять или удалять произвольный элемент.</description>
    </item>
    <item>
      <title>8. Хеширование</title>
      <link>https://apmath-spbu.github.io/basics/hashing/index.html</link>
      <pubDate>Sun, 02 Mar 2025 11:30:34 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/hashing/index.html</guid>
      <description>Хеш-таблица Пусть мы хотим поддерживать множество $A$ элементов - ключей, то есть уметь добавлять ключ в $A$, удалять ключ из $A$, а также искать ключ в $A$. Мы будем считать, что все ключи берутся из множества $U=\{0,1, \ldots,|U|-1\}$.&#xA;✍️ В общем случае ключами могут быть какие угодно объекты, которым можно каким-либо образом сопоставить числа (например, строки).&#xA;Если $|U|$ не очень велико, можно просто создать массив размера $|U|$ и хранить каждый ключ в ячейке с номером, равным этому ключу. Чтобы понимать, каких ключей в $A$ нет, в соответствующих ячейках будем хранить специальное значение, не равное ни одному из ключей, например, -1 . Тогда все операции можно осуществлять за $O(1)$.</description>
    </item>
    <item>
      <title>9. Арифметика сравнений</title>
      <link>https://apmath-spbu.github.io/basics/numerical_algos_arithmetic_comparison/index.html</link>
      <pubDate>Sat, 15 Mar 2025 19:04:59 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/numerical_algos_arithmetic_comparison/index.html</guid>
      <description>Начиная с этой части, при оценке сложности алгоритмов будем использовать обозначение $M(n)$, имея в виду сложность умножения двух чисел длины $n$. Можно показать (с помощью метода Ньютона), что деление нацело имеет ту же сложность, что и умножение, поэтому для деления отдельного обозначения вводить не будем.&#xA;Сложение и умножение по модулю Сложение и умножение по $n$-битному модулю $N$ имеет ту же сложность, что и обычные сложение и умножение, то есть $O(n)$ и $O(M(n))$ : нужно произвести вычисление без модуля, при этом результат будем иметь не более $2 n$ бит, после чего вычислить остаток от деления результата на $N$. В случае сложения результат меньше $2 N$, поэтому достаточно просто (возможно) вычесть $N$, что требует ещё $O(n)$ операций и не увеличивает оценку времени работы. В случае умножения осуществляем деление с остатком за $O(M(n))$.</description>
    </item>
    <item>
      <title>10. Проверка на простоту и факторизация</title>
      <link>https://apmath-spbu.github.io/basics/numerical_algos_prime_test_and_factorization/index.html</link>
      <pubDate>Sat, 15 Mar 2025 19:04:58 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/numerical_algos_prime_test_and_factorization/index.html</guid>
      <description>Решето Эратосфена Решето Эратосфена - алгоритм, находящий все простые числа, не превосходящие некоторой границы $n$. Алгоритм рассматривает последовательно все числа от 2 до $n$. Если очередное число ещё не помечено как составное, он помечает его как простое, а все числа, делящиеся на него, помечает как составные.&#xA;Поскольку у любого составного числа $x$ есть делитель, не больший корня из $x$, достаточно перебирать кратные простого числа, начиная с его квадрата.&#xA;1 2 3 4 5 6 vector&lt;bool&gt; isPrime(n + 1, 1) isPrime[0] = isPrime[1] = 0 for i = 2..n: if isPrime[i]: for (j = i * i; j &lt;= n; j += i): isPrime[j] = 0 Время работы алгоритма есть</description>
    </item>
    <item>
      <title>11. Криптография</title>
      <link>https://apmath-spbu.github.io/basics/numerical_algos_cryptography/index.html</link>
      <pubDate>Sat, 15 Mar 2025 19:04:57 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/numerical_algos_cryptography/index.html</guid>
      <description>Одна из классических задач криптографии звучит следующим образом. Есть Алиса и Боб, которые хотят поговорить без свидетелей. Также есть Ева (от англ. eavesdropper), которая их подслушивает. Алиса и Боб хотят, чтобы Ева, даже если она подслушает все сообщения, не поняла, о чём был разговор.&#xA;Более формально, пусть Алиса хочет послать Бобу секретное сообщение - битовую строку $x$. Она шифрует её с помощью некоторой функции $E(\cdot)$ (от англ. encoder) и посылает Бобу зашифрованное сообщение $E(x)$. Боб использует функцию $D(\cdot)$ (от англ. decoder), чтобы восстановить исходное сообщение: $D(E(x))=x$.</description>
    </item>
    <item>
      <title>12. Графы. Определения и способы хранения</title>
      <link>https://apmath-spbu.github.io/basics/graph_definition/index.html</link>
      <pubDate>Sat, 15 Mar 2025 19:04:56 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/graph_definition/index.html</guid>
      <description>Определения Граф задаётся множеством вершин $V$ и множеством рёбер $E$, соединяющих пары вершин (в английском языке граф - graph, вершина - vertex или node, ребро - edge).&#xA;В ориентированном (directed graph, digraph) графе каждое ребро имеет направление, то есть является упорядоченной парой вершин (может быть ребро из вершины $a$ в вершину $b$, но не быть ребра из $b$ в $a$ ). В неориентированном (undirected) графе рёбра направлений не имеют, то есть являются неупорядоченными парами (считаем, что ребро, ведущее из $a$ в $b$, ведёт и из $b$ в $a$ тоже).</description>
    </item>
    <item>
      <title>13. Графы. Поиск в глубину</title>
      <link>https://apmath-spbu.github.io/basics/graph_depth_search/index.html</link>
      <pubDate>Sat, 15 Mar 2025 19:04:55 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/graph_depth_search/index.html</guid>
      <description>Большая часть рассуждений применима как к ориентированным, так и к неориентированным графам (если не сказано обратное); допускаются кратные рёбра и петли (если не сказано обратное).&#xA;Обход вершин, достижимых из данной Поиск в глубину (depth-first search, DFS) по вершине $w \in V$ находит множество вершин, достижимых из неё, то есть таких, в которые можно попасть, сделав несколько переходов по рёбрам, начиная из вершины $w$.&#xA;Изначально алгоритм запускается от вершины $w$. Он перебирает исходящие из текущей вершины рёбра и смотрит, куда они ведут. Каждый раз, когда алгоритм встречает ещё не посещённую вершину, он запускается от неё рекурсивно, а после возврата из рекурсии продолжает перебирать рёбра, исходящие из текущей вершины.</description>
    </item>
    <item>
      <title>14. Графы. Алгоритмы поиска кратчайших путей</title>
      <link>https://apmath-spbu.github.io/basics/graph_shortest_path_algos/index.html</link>
      <pubDate>Wed, 12 Mar 2025 09:30:55 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/graph_shortest_path_algos/index.html</guid>
      <description>Во взвешенном графе (weighted graph) каждое ребро имеет вес (weight) $w_{e}$. В зависимости от задачи, веса могут быть как целыми, так и вещественными; иногда допускаются отрицательные веса.&#xA;Длина (length) пути во взвешенном графе - это сумма весов рёбер на пути. Можно считать, что все рёбра в невзвешенном графе имеют вес, равный единице. Тогда длина пути в невзвешенном графе - это просто количество рёбер в этом пути. Кратчайший путь (shortest path) между двумя вершинами - это путь минимальной длины между этими вершинами (путь с минимальным числом рёбер в невзвешенном случае). Расстояние (distance) между вершинами - длина кратчайшего пути между ними. Если пути между вершинами нет, расстояние считается бесконечным.</description>
    </item>
    <item>
      <title>15. Жадные алгоритмы</title>
      <link>https://apmath-spbu.github.io/basics/greedy_algorithms/index.html</link>
      <pubDate>Fri, 18 Apr 2025 17:02:24 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/greedy_algorithms/index.html</guid>
      <description>Алгоритм Хаффмана Алгоритм Хаффмана (Huffman, 1952) - один из самых известных алгоритмов сжатия текста. Пусть дан текст, состоящий из символов алфавита $\Sigma$, который мы хотим закодировать как можно более короткой последовательностью бит.&#xA;Префиксные коды Самый простой способ - кодировать каждый символ уникальной последовательностью из $k$ бит (будем называть такую последовательность кодовым словом (codeword)), где $2^{k} \geqslant|\Sigma|$ (чтобы такое кодирование вообще было возможно). Такой способ не всегда эффективен: например, пусть $\Sigma=\{a, b, c, d\}$, текст имеет длину 10000 , но большая часть символов текста равна $a$ (скажем, $a$ встречается в тексте 7000 раз, а остальные символы по 1000 раз). Тогда вышеописанный способ кодирования потребует $20000$ бит. Если же кодовое слово символа $а$ будет равно $0$ , символа $b-10, c-110, d-111$, то суммарно потребуется лишь $7000 \cdot 1+1000 \cdot 2+1000 \cdot 3+1000 \cdot 3=15000$ бит.</description>
    </item>
    <item>
      <title>Поиск минимального остовного дерева</title>
      <link>https://apmath-spbu.github.io/basics/finding_the_minimum_spanning_tree/index.html</link>
      <pubDate>Sun, 20 Apr 2025 13:55:32 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/finding_the_minimum_spanning_tree/index.html</guid>
      <description>Остовное дерево (spanning tree), или остов, связного неориентированного графа - это остовный подграф этого графа, являющийся деревом, или, другими словами, связный остовный подграф без циклов. Вес $w(T)$ остова $T$ взвешенного графа - это сумма весов его рёбер.&#xA;Пусть дан связный неориентированный граф с неотрицательными весами рёбер, и мы хотим выбрать подмножество рёбер как можно меньшего суммарного веса, с помощью которого можно было бы добраться из любой вершины в любую. Если в подмножестве рёбер есть цикл, из него всегда можно выкинуть одно из рёбер, не увеличив суммарный вес и не нарушив связности. Значит, мы хотим найти остовное дерево минимально возможного веса, или минимальное остовное дерево (minimum spanning tree).</description>
    </item>
    <item>
      <title>Динамическое программирование</title>
      <link>https://apmath-spbu.github.io/basics/dynamic_programming/index.html</link>
      <pubDate>Thu, 24 Apr 2025 15:33:10 +0300</pubDate>
      <guid>https://apmath-spbu.github.io/basics/dynamic_programming/index.html</guid>
      <description>Поиск кратчайшего пути в ациклическом ориентированном графе Пусть перед нами стоит задача поиска кратчайших путей от вершины $s$ до всех остальных вершин в ациклическом ориентированном графе. Конечно, можно воспользоваться одним из уже изученных алгоритмов. Есть, однако, и более простое решение с линейным временем работы.&#xA;Для любой вершины $v \neq s$ верно следующее равенство:&#xA;$$ \operatorname{dist}[v]=\min \left\{d i s t[u]+w_{e}: e=(u, v) \in E\right\} $$Будем перебирать вершины в порядке топологической сортировки. Тогда все значения dist, встречающиеся в выражении справа, к моменту рассмотрения вершины $v$ уже будут найдены.</description>
    </item>
  </channel>
</rss>