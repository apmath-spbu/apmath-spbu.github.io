var relearn_searchindex = [
  {
    "breadcrumb": "",
    "content": "This is a new chapter.",
    "description": "This is a new chapter.",
    "tags": [],
    "title": "Basics",
    "uri": "/basics/index.html"
  },
  {
    "breadcrumb": "Basics",
    "content": "1. Вычисление чисел Фибоначчи Последовательность чисел Фибоначчи\n$$ 1,1,2,3,5,8,13,21,34,55,89, \\ldots $$определяется следующим образом:\nОпределение 1.1.1 $F_{n}$ - $n$-ое число Фибоначчи, где $F_{0}=F_{1}=1, F_{n}=F_{n-1}+F_{n-2}, n\u003e1 .$\nЧисла Фибоначчи растут экспоненциально быстро:\nЛемма 1.1.1 $2^{\\lfloor n / 2\\rfloor} \\leqslant F_{n} \\leqslant 2^{n}$. Доказательство Докажем утверждение по индукции.\nБаза. Утверждение верно для $n=0,1$.\nПереход. Пусть $n\u003e1$, тогда $F_{n}=F_{n-1}+F_{n-2} \\leqslant 2^{n-1}+2^{n-2}\u003c2^{n}$.\nС другой стороны, $F_{n} \\geqslant 2 \\cdot F_{n-2} \\geqslant 2 \\cdot 2^{\\lfloor(n-2) / 2\\rfloor}=2^{\\lfloor n / 2\\rfloor}$.\nЭкспоненциальный алгоритм Следующий рекурсивный алгоритм вычисляет $n$-ое число Фибоначчи, точно следуя определению:\nfib(n): if n \u003c= 1: return 1 return fib(n - 1) + fib(n - 2) Каково время работы этого алгоритма? Оценим $T(n)$ - суммарное количество вызовов fib , происходящих при выполнении $\\mathrm{fib}(\\mathrm{n})$ : если $n \\leqslant 1$, то $T(n)=1$; иначе\n$$ T(n)=1+T(n-1)+T(n-2) . $$Несложно доказать по индукции, что $F_{n} \\leqslant T(n)\u003c2 F_{n}$. В каждом вызове fib совершается ограниченное число (скажем, не больше пяти) операций, поэтому время работы алгоритма примерно пропорционально $F_{n}$ (чуть позже у нас появится формальное определение этого “примерно”).\nИз леммы 1.1.1 следует, например, что, $F_{300} \\geqslant 2^{150}\u003e10^{45}$. На компьютере, выполняющем $10^{9}$ операций в секунду, fib(300) будет выполняться больше $10^{36}$ секунд.\nПолиномиальный алгоритм Посмотрим на дерево рекурсивных вызовов алгоритма fib (рис. 1.1). Видно, что алгоритм много раз вычисляет одно и то же. Давайте сохранять результаты промежуточных вычислений в массив: Рис. 1.1: Дерево рекурсивных вызовов fib\nfibFast(n): if n \u003c= 1: return 1 int f[n + 1] # создаём массив с индексами 0..n f[0] = f[1] = 1 for i = 2..n: f[i] = f[i - 1] + f[i - 2] return f[n] На каждой итерации цикла совершается одно сложение, всего итераций примерно $n$, поэтому количество сложений, выполняемых в ходе нового алгоритма, примерно пропорционально $n$. Есть ещё одна тонкость - из леммы 1.1.1 следует, что двоичная запись $F_{n}$ имеет длину порядка $n$. Чуть позже мы увидим, что сложение двух $n$-битовых чисел требует порядка $n$ элементарных операций, значит общее время работы нового алгоритма примерно пропорционально $n^{2}$. С помощью fibFast можно уже за разумное время вычислить не только $F_{300}$, но и $F_{100000}$.\n1.2 О-символика Хорошо себя зарекомендовал и стал общепринятым следующий подход - оценивать время работы алгоритма некоторой функцией от входных параметров, при этом пренебрегая ограниченными множителями. Это позволяет эффективно сравнивать алгоритмы между собой, при этом не нужно заниматься точным подсчётом количества элементарных операций. Примерно так мы и рассуждали об алгоритмах вычисления чисел Фибоначчи. Введём несколько обозначений, которые помогут проводить подобные рассуждения более кратко и точно.\nВремя работы алгоритма - это, конечно, всегда неотрицательная функция. Тем не менее, мы даём следующие определения для функций, принимающих произвольные вещественные значения, поскольку такие функции часто возникают в процессе рассуждений.\nОпределение 1.2.1 Рассмотрим функции $f, g: \\mathbb{N} \\rightarrow \\mathbb{R}$.\n$f=O(g)$, если существуют такие $C\u003e0, N\u003e0$, что для любого $n\u003eN$ : $|f(n)| \\leqslant C \\cdot|g(n)|$. $f=\\Omega(g)$, если существуют такие $C\u003e0, N\u003e0$, что для любого $n\u003eN$ : $|f(n)| \\geqslant C \\cdot|g(n)|$. $f=\\Theta(g)$, если существуют такие $C_{1}\u003e0, C_{2}\u003e0, N\u003e0$, что для любого $n\u003eN$ : $C_{1} \\cdot|g(n)| \\leqslant|f(n)| \\leqslant C_{2} \\cdot|g(n)|$. Запись $f=O(g)$ можно понимать как \" $|f| \\leqslant|g|$ с точностью до константы\". Аналогично, $\\Omega(\\cdot)$ можно считать аналогом $\\geqslant$, а $\\Theta(\\cdot)$ - аналогом $=$. Ещё один способ понимать запись $f=O(g)$ - отношение $\\frac{|f(n)|}{|g(n)|}$ ограничено сверху некоторой константой.\nМногие естественные свойства операторов сравнения $\\leqslant,=, \\geqslant$ выполняются и для их асимптотических аналогов. Сформулируем некоторые из этих свойств:\nСвойства 1.2.1 $f=\\Theta(g)$ тогда и только тогда, когда $f=O(g)$ и $f=\\Omega(g)$.\n$f=O(g)$ тогда и только тогда, когда $g=\\Omega(f)$.\n$f=\\Theta(g)$ тогда и только тогда, когда $g=\\Theta(f)$.\nСуществуют также асимптотические аналоги $\u003c$ и $\u003e: o(\\cdot)$ и $\\omega(\\cdot)$. Определение 1.2.2 Рассмотрим функции $f, g: \\mathbb{N} \\rightarrow \\mathbb{R}$.\n$f=o(g)$, если для любого $C\u003e0$ найдётся такое $N\u003e0$, что для любого $n\u003eN$ : $|f(n)| \\leqslant C \\cdot|g(n)|$.\n$f=\\omega(g)$, если для любого $C\u003e0$ найдётся такое $N\u003e0$, что для любого $n\u003eN$ : $|f(n)| \\geqslant C \\cdot|g(n)|$.\nЗапись $f=o(g)$ можно понимать как “отношение $\\frac{|f(n)|}{|g(n)|}$ стремится к нулю с увеличением $n$ “, а запись $f=\\omega(g)$ - как “отношение $\\frac{|f(n)|}{|g(n)|}$ стремится к бесконечности с увеличением $n$ “.\nСвойства 1.2.2 $f=o(g)$ тогда и только тогда, когда $g=\\omega(f)$. Если $f=O(g)$ и $g=O(h)$, то $f=O(h)$. То же верно для $\\Omega, \\Theta, o, \\omega$. Если $f=O(g), g=o(h)$, то $f=o(h)$. Если $f=\\Omega(g), g=\\omega(h)$, то $f=\\omega(h)$. Если $f=O(h)$ и $g=O(h)$, то $f+g=O(h)$. То же верно для $o$. Если $f, g \\geqslant 0$, то то же верно и для $\\Omega, \\Theta, \\omega$. Если $f=o(g)$, то $f+g=\\Theta(g)$. Если $f, g \\geqslant 0, f=O(g)$, то $f+g=\\Theta(g)$. Для любого $C \\neq 0$ верно $C \\cdot f=\\Theta(f)$. Заметим, что у последних трёх свойств нет аналогов для обычных операторов сравнения.\nДоказательство Докажем для примера п. 3 (вариант с $O$ и $о$).\nНужно показать, что для любого $C\u003e0$ найдётся $N\u003e0$, что для любого $n\u003eN$ : $|f(n)| \\leqslant C \\cdot|h(n)|$. Зафиксируем $C\u003e0$.\n$f=O(g)$, поэтому найдутся $C_{1}\u003e0, N_{1}\u003e0$, что для любого $n\u003eN_{1}:|f(n)| \\leqslant C_{1} \\cdot|g(n)|$. $g=o(h)$, поэтому найдётся такое $N_{2}\u003e0$, что для любого $n\u003eN_{2}:|g(n)| \\leqslant \\frac{C}{C_{1}} \\cdot|h(n)|$.\nТогда для любого $n\u003e\\max \\left(N_{1}, N_{2}\\right):|f(n)| \\leqslant C_{1} \\cdot|g(n)| \\leqslant C_{1} \\cdot \\frac{C}{C_{1}} \\cdot|h(n)|=C \\cdot|h(n)|$.\nВернемся к алгоритмам вычисления чисел Фибоначчи. Пользуясь новыми обозначениями, мы показали, что время работы fibFast(n) можно оценить как $O\\left(n^{2}\\right)$. При этом время работы $\\mathrm{fib}(\\mathrm{n})$ можно оценить (сверху) как $O\\left(2^{n} \\cdot n\\right)$, и (снизу) как $\\Omega\\left(2^{\\lfloor n / 2\\rfloor}\\right)$.\n1.3 Многочлены, экспоненты и логарифмы Очень часто время работы алгоритма удаётся оценить функцией, являющейся комбинацией каких-то из трёх базовых типов: многочленов, экспонент и логарифмов. Так, время работы fibFast мы оценили многочленом $n^{2}$, а время работы fib - произведением экспоненты на многочлен: $2^{n} \\cdot n$. В связи с этим полезно изучить асимптотические свойства этих функций и научиться сравнивать их между собой.\nЛемма 1.3.1 Для любых $l\u003ek$ верно $n^{k}=o\\left(n^{l}\\right)$. Доказательство Для любого $C\u003e0$, при $n \\geqslant\\left(\\frac{1}{C}\\right)^{\\frac{1}{l-k}}$ верно\n$$ n^{k} \\leqslant C \\cdot \\frac{1}{C} \\cdot n^{k} \\leqslant C \\cdot n^{l-k} \\cdot n^{k}=C \\cdot n^{l} $$ Определение 1.3.1 Многочлен - это функция, которую можно записать в виде\n$$ f(n)=a_{0}+a_{1} n+a_{2} n^{2}+\\cdots+a_{d} n^{d} $$для некоторого $d \\geqslant 0$, так, что $a_{d} \\neq 0$. Это $d$ называют степенью многочлена и обозначают как $\\operatorname{deg}(f)$.\nСледствие 1.3.2 Пусть $f(n)$ - многочлен степени $d$. Тогда $f(n)=\\Theta\\left(n^{d}\\right)$. Доказательство Пусть $f(n) = a_{0} + a_{1} n + a_{2} n^{2} + \\cdots + a_{d} n^{d}$. Из леммы 1.3.1 и п. 6 предложения 1.2.2 следует, что $a_{j} n^{j} = o\\left(n^{d}\\right)$ для любого $0 \\leqslant j",
    "description": "1. Вычисление чисел Фибоначчи Последовательность чисел Фибоначчи\n$$ 1,1,2,3,5,8,13,21,34,55,89, \\ldots $$определяется следующим образом:\nОпределение 1.1.1 $F_{n}$ - $n$-ое число Фибоначчи, где $F_{0}=F_{1}=1, F_{n}=F_{n-1}+F_{n-2}, n\u003e1 .$\nЧисла Фибоначчи растут экспоненциально быстро:\nЛемма 1.1.1 $2^{\\lfloor n / 2\\rfloor} \\leqslant F_{n} \\leqslant 2^{n}$. Доказательство Докажем утверждение по индукции.",
    "tags": [],
    "title": "1. Анализ сложности алгоритмов",
    "uri": "/basics/complexity/index.html"
  },
  {
    "breadcrumb": "Basics",
    "content": "Современные компьютеры умеют за одну элементарную операцию складывать два 32(или 64)-битных числа. Часто (например, в криптографии) приходится работать с куда более длинными числами. Поговорим о том, как проводить с ними элементарные арифметические операции.\nДля удобства будем считать, что на вход алгоритмам даются натуральные числа в двоичной записи. Мы будем работать с числами, имеющими двоичную запись длины $n$ (возможно, с ведущими нулями).\nВ произвольном случае можно применить соответствующий алгоритм для $n$ равного максимуму из длин чисел, а в конце определить длину записи результата применения операции (удалить ведущие нули), что потребует $O(n)$ операций и не повлияет на оценку сложности алгоритма.\n2.1 Сложение Используем всем знакомый со школы способ сложения чисел в столбик:\nadd(a, b, n): # a и b - двоичные записи чисел int c[n + 1] = 0 # создаём и заполняем нулями массив, куда запишем ответ for i = 0..n - 1: c[i] = a[i] + b[i] if c[i] \u003e= 2: c[i + 1] += 1, c[i] -= 2 return c Время работы алгоритма - $O(n)$, существенно быстрее нельзя, потому что столько времени занимает уже считывание входных данных или вывод ответа.\nАналогичный алгоритм можно написать для чисел, записанных в $b$-ичной системе счисления. Если сумма трёх $b$-ичных чисел помещается в 32(64)-битный тип данных, то алгоритм всё ещё будет корректен. При этом $n$-битное число будет иметь примерно $\\frac{n}{\\log b}$ цифр в $b$-ичной записи, то есть алгоритм будет работать за $O\\left(\\frac{n}{\\log b}\\right)=O(n)$, так как $\\frac{1}{\\log b}$ - это константа. Тем не менее, это может дать ускорение в несколько десятков раз, что безусловно бывает полезно на практике.\n2.2 Умножение Вспомним теперь и школьное умножение чисел в столбик (заметим лишь, что ответ имеет длину не больше $2 n$, поскольку $\\left.\\left(2^{n}-1\\right) \\cdot\\left(2^{n}-1\\right)\u003c2^{2 n}\\right)$ :\nmultiply(a, b, n): # a и b - двоичные записи чисел int c[2 * n] = 0 # создаём и заполняем нулями массив, куда запишем ответ for i = 0..n - 1: for j = 0..n - 1: c[i + j] += a[i] * b[j] for i = 0..2 * n - 2: if c[i] \u003e= 2: c[i + 1] += c[i] / 2 c[i] %= 2 return c Из-за двух вложенных циклов время работы этого алгоритма - уже $O\\left(n^{2}\\right)$. Приведём альтернативный рекурсивный алгоритм умножения двух чисел, пользующийся следующим правилом:\n$$ a \\cdot b= \\begin{cases}2 \\cdot\\left(a \\cdot\\left\\lfloor\\frac{b}{2}\\right\\rfloor\\right), \u0026 \\text { если } b \\text { чётно, } \\\\ a+2 \\cdot\\left(a \\cdot\\left\\lfloor\\frac{b}{2}\\right\\rfloor\\right), \u0026 \\text { иначе. }\\end{cases} $$multiply(a, b): # a и b - двоичные записи чисел if b == 0: return 0 c = multiply(a, b / 2) # деление нацело if b % 2 == 0: return 2 * c else: return 2 * c + a В этой схематичной записи под делением на два имеется ввиду битовый сдвиг вправо (то есть взятие двоичной записи без младшего бита), под умножением на два - битовый сдвиг влево (добавление нуля в начало битовой записи). Остаток по модулю два - это младший бит числа.\nАлгоритм произведёт $O(n)$ рекурсивных вызовов, поскольку при каждом вызове длина битовой записи $b$ уменьшается на один. В каждом вызове функции происходят битовый сдвиг влево, битовый сдвиг вправо, и, возможно сложение - всего $O(n)$ элементарных операций. Таким образом, общее время работы снова $O\\left(n^{2}\\right)$.\nЗаметим, что если длины битовых записей $a$ и $b$ равны $n$ и $m$, то время работы обоих алгоритмов можно оценить как $O(n m)$.\n2.3 Деление Пусть теперь мы хотим поделить $a$ на $b$, то есть найти такие $q, r$, что $a=q b+r$ и $0 \\leqslant r",
    "description": "Современные компьютеры умеют за одну элементарную операцию складывать два 32(или 64)-битных числа. Часто (например, в криптографии) приходится работать с куда более длинными числами. Поговорим о том, как проводить с ними элементарные арифметические операции.\nДля удобства будем считать, что на вход алгоритмам даются натуральные числа в двоичной записи. Мы будем работать с числами, имеющими двоичную запись длины $n$ (возможно, с ведущими нулями).\nВ произвольном случае можно применить соответствующий алгоритм для $n$ равного максимуму из длин чисел, а в конце определить длину записи результата применения операции (удалить ведущие нули), что потребует $O(n)$ операций и не повлияет на оценку сложности алгоритма.",
    "tags": [],
    "title": "2. Элементарная арифметика",
    "uri": "/basics/elementary_arithmetic/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Категории",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Теги",
    "uri": "/tags/index.html"
  }
]
